{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('UBID:          hnitturk')\n",
    "print('Person Number: 50291411')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load USPS data from file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'USPSdata/Test'\n",
    "savedImg = []\n",
    "curFolderPath = curPath\n",
    "imgs =  os.listdir(curFolderPath)\n",
    "imgs.sort()\n",
    "for img in imgs:\n",
    "    #print(img)\n",
    "    curImg = curFolderPath + '/' + img\n",
    "    if curImg[-3:] == 'png':\n",
    "        img = Image.open(curImg,'r')\n",
    "        \n",
    "        #resizing the image\n",
    "        img = img.resize((28, 28))\n",
    "        \n",
    "        #grayscaling the image\n",
    "        imgdata = (255-np.array(img.getdata()))/255\n",
    "        USPSMat.append(imgdata)       \n",
    "for i in range(9,-1,-1):\n",
    "    for j in range(150):\n",
    "        USPSTar.append(i)\n",
    "        \n",
    "#function for one hoht encoding of the target variables        \n",
    "def oneHotIt(Y):\n",
    "    m = Y.shape[0]\n",
    "    OHV = scipy.sparse.csr_matrix((np.ones(m), (Y, np.array(range(m)))))\n",
    "    OHV = np.array(OHV.todense()).T\n",
    "    return OHV\n",
    "\n",
    "usps_x_nn = np.asarray(USPSMat)\n",
    "y = np.asarray(USPSTar)\n",
    "usps_y_nn = oneHotIt(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=10\n",
    "image_vector_size=28*28\n",
    "x_train_nn = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test_nn = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "y_train_nn = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_nn = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 784 \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating hidden layer\n",
    "model.add(Dense(units=32, activation='relu', input_shape=(image_size,)))\n",
    "\n",
    "#creating output layer\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "#ptimizer used is stochastic gradient and cross entropy loss\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsize=[64,128,150,200,250]\n",
    "for i in bsize:\n",
    "    print(\"batch_size:\",i)\n",
    "    print(\"epochs: 150\" )\n",
    "    \n",
    "    #Training\n",
    "    history = model.fit(x_train_nn, y_train_nn, batch_size=i, epochs=150, verbose=False,validation_split=0.1)\n",
    "    \n",
    "    #predicting\n",
    "    y_pred = model.predict_classes(x_test_nn)\n",
    "    \n",
    "    #confusion_matrix\n",
    "    print(confusion_matrix(y_test_nn, y_pred))\n",
    "    \n",
    "    #testing or evaluating the model\n",
    "    loss,accuracy = model.evaluate(x_test_nn, y_test_nn, verbose=False)\n",
    "    print(\"Loss: \", loss)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    loss,accuracy = model.evaluate(usps_x_nn, usps_y_nn, verbose=False)\n",
    "    print(\"Loss: \", loss)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "epochsize=[150,100,200,50,250]\n",
    "for i in epochsize:\n",
    "    print(\"number of epochs:\",i)\n",
    "    \n",
    "    #Training\n",
    "    history = model.fit(x_train_nn, y_train_nn, batch_size=128, epochs=i, verbose=False,validation_split=0.1)\n",
    "    \n",
    "    #predicting\n",
    "    y_pred = model.predict_classes(x_test_nn)\n",
    "    \n",
    "    #confusion_matrix\n",
    "    print(confusion_matrix(y_test_nn, y_pred))  \n",
    "    \n",
    "    #testing or evaluating the model\n",
    "    loss,accuracy = model.evaluate(x_test_nn, y_test_nn, verbose=False)\n",
    "    print(\"Loss:\", loss)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    loss,accuracy = model.evaluate(usps_x_nn, usps_y_nn, verbose=False)\n",
    "    print(\"Loss: \", loss)\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM and Random Forest  - Keras - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching MNIST data\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the data\n",
    "\n",
    "n_train = 60000\n",
    "n_test = 10000\n",
    "indices = np.arange(len(mnist.data))\n",
    "train_idx = np.arange(0,n_train)\n",
    "test_idx = np.arange(n_train,n_train+n_test)\n",
    "X_train_svmrf, y_train_svmrf = mnist.data[train_idx], mnist.target[train_idx]\n",
    "X_test_svmrf, y_test_svmrf = mnist.data[test_idx], mnist.target[test_idx]\n",
    "usps_y_svmrf = y\n",
    "usps_x = usps_x_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM classifiers using various combinations of parameters such as kernel, degree, gamma and C\n",
    "\n",
    "print(\"Kernal: linear\")\n",
    "classifier1 = SVC(kernel='linear', C=1.0, degree=3, gamma= 0.1)\n",
    "classifier1.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_svm=classifier1.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf, y_pred_mnist_svm))\n",
    "\n",
    "y_pred_usps_svm=classifier1.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_svm))\n",
    "\n",
    "print(\"Kernal: polynomial\")\n",
    "classifier1 = SVC(kernel='poly', C=0.2, degree=2, gamma= 0.1)\n",
    "classifier1.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_svm=classifier1.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf, y_pred_mnist_svm))\n",
    "\n",
    "y_pred_usps_svm=classifier1.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_svm))\n",
    "\n",
    "print(\"Kernal: rbf\")\n",
    "classifier1 = SVC(kernel='rbf', C=1.0, degree=1, gamma=0.1)\n",
    "classifier1.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_svm=classifier1.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf,y_pred_mnist_svm))\n",
    "\n",
    "y_pred_usps_svm=classifier1.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_svm))\n",
    "\n",
    "\n",
    "print(\"Kernal: rbf\")\n",
    "classifier1 = SVC(kernel='rbf', C=1.0, degree=1, gamma=1)\n",
    "classifier1.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_svm=classifier1.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf,y_pred_mnist_svm))\n",
    "\n",
    "y_pred_usps_svm=classifier1.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_svm))\n",
    "\n",
    "\n",
    "print(\"Kernal: sigmoid\")\n",
    "classifier1 = SVC(kernel='sigmoid', C=1.0, degree=1, gamma=0.1)\n",
    "classifier1.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_svm=classifier1.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf, y_pred_mnist_svm))\n",
    "\n",
    "y_pred_usps_svm=classifier1.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest classifiers using various combinations of parameters such as n_estimators, criterion, max depth,\n",
    "#min_samples_split\n",
    "\n",
    "classifier2 = RandomForestClassifier(n_estimators=200, criterion=\"gini\", max_depth = 2, min_samples_split = 10)\n",
    "classifier2.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_rf = classifier2.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf, y_pred_mnist_rf))\n",
    "\n",
    "y_pred_usps_rf = classifier2.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = RandomForestClassifier(n_estimators=300,criterion=\"entropy\",max_depth = 2,min_samples_split = 10)\n",
    "classifier2.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_rf = classifier2.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf, y_pred_mnist_rf))\n",
    "\n",
    "y_pred_usps_rf = classifier2.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = RandomForestClassifier(n_estimators=400, criterion=\"gini\",max_depth = 2, min_samples_split = 10)\n",
    "classifier2.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_rf = classifier2.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf, y_pred_mnist_rf))\n",
    "\n",
    "y_pred_usps_rf = classifier2.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = RandomForestClassifier(n_estimators=500,criterion=\"entropy\",max_depth = 2,min_samples_split = 10)\n",
    "classifier2.fit(X_train_svmrf, y_train_svmrf)\n",
    "\n",
    "y_pred_mnist_rf = classifier2.predict(X_test_svmrf)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_svmrf, y_pred_mnist_rf))\n",
    "\n",
    "y_pred_usps_rf = classifier2.predict(usps_x)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(usps_y_svmrf, y_pred_usps_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import random\n",
    "import scipy.sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST data\n",
    "X_train, y_train = loadlocal_mnist(images_path='train-images.idx3-ubyte', labels_path='train-labels.idx1-ubyte')\n",
    "\n",
    "X_test, y_test = loadlocal_mnist(images_path='t10k-images.idx3-ubyte', labels_path='t10k-labels.idx1-ubyte')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load USPS on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding for target variables\n",
    "def oneHotIt(Y):\n",
    "    targets = np.array(Y).reshape(-1)\n",
    "    ohv = np.eye(10)[targets]\n",
    "    return ohv \n",
    "\n",
    "#initialize weights\n",
    "def init_params(dimension,y):\n",
    "    w = np.zeros((dimension, len(np.unique(y))))\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    sm = (np.exp(z).T / np.sum(np.exp(z),axis=1)).T\n",
    "    return sm\n",
    "\n",
    "def propagate(w, b, X, Y,epochs, lr):\n",
    "    #training\n",
    "    \n",
    "    # num of training samples\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    #one-hot encoding the data\n",
    "    y_ohv = oneHotIt(Y)\n",
    "    for i in range(epochs):\n",
    "        lam = 1\n",
    "        \n",
    "        # forward pass\n",
    "        A = softmax(np.dot(X,w))\n",
    "        \n",
    "        #loss function\n",
    "        loss = -((1 / m) *np.sum(y_ohv * np.log(A))) #We then find the loss of the probabilities\n",
    "        \n",
    "        # back propagation - calculating the gradient\n",
    "        dw = (1/m)*(np.dot(X.T, (y_ohv-A)))+lam*w\n",
    "        db = (np.sum(A-y_ohv))\n",
    "\n",
    "        #update rule for weight and bias\n",
    "        w = w-(lr*dw)\n",
    "        b = b-(lr*db)\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def predict(w, b, X):    \n",
    "    #make predictions\n",
    "    A = softmax(np.dot(X,w))    \n",
    "    Y_predict = np.argmax(A,axis=1)   \n",
    "    return A, Y_predict\n",
    "\n",
    "def getAccuracy(w,b,someX,someY):\n",
    "    \n",
    "    #get accuracy\n",
    "    prob,pred = predict(w,b,someX)\n",
    "    accuracy = sum(pred == someY)/(float(len(someY)))\n",
    "    return accuracy\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, epochs, lr):\n",
    "    w, b = init_params(X_train.shape[1], Y_train)\n",
    "    w, b = propagate(w, b, X_train, Y_train, epochs, lr)\n",
    "    print(getAccuracy(w,b,X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myModel = model(X_train, y_train, X_test, y_test, 1000, 1e-3)\n",
    "myModel = model(X_train, y_train, X_test, y_test, 1500, 1e-3)\n",
    "myModel = model(X_train, y_train, X_test, y_test, 2000, 1e-3)\n",
    "myModel = model(X_train, y_train, X_test, y_test, 1000, 1e-4)\n",
    "myModel = model(X_train, y_train, X_test, y_test, 1000, 1e-2)\n",
    "myModel = model(X_train, y_train, X_test, y_test, 1000, 1e-1)\n",
    "\n",
    "\n",
    "myModel = model(X_train, y_train, usps_x, y, 1000, 1e-3)\n",
    "myModel = model(X_train, y_train, usps_x, y, 1500, 1e-3)\n",
    "myModel = model(X_train, y_train, usps_x, y, 2000, 1e-3)\n",
    "myModel = model(X_train, y_train, usps_x, y, 1000, 1e-4)\n",
    "myModel = model(X_train, y_train, usps_x, y, 1000, 1e-2)\n",
    "myModel = model(X_train, y_train, usps_x, y, 1000, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "X_train_svmrf, y_train_svmrf = mnist.data[train_idx], mnist.target[train_idx]\n",
    "X_test_svmrf, y_test_svmrf = mnist.data[test_idx], mnist.target[test_idx]\n",
    "\n",
    "a = list(zip(X_train_svmrf,y_train_svmrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nn = random.sample(a,15000)\n",
    "x,y = zip(*sample_nn)\n",
    "x1 = np.asarray(x)\n",
    "y1 = np.asarray(y)\n",
    "y2 = keras.utils.to_categorical(np.asarray(y), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 784 \n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=32, activation='sigmoid', input_shape=(image_size,)))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x1, y2, batch_size=128, epochs=150, verbose=False,validation_split=0.1)\n",
    "ynew_mnist_nn_bg = model.predict_classes(X_test_svmrf)\n",
    "ynew_usps_nn_bg = model.predict_classes(usps_x_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nn = random.sample(a,15000)\n",
    "x,y = zip(*sample_nn)\n",
    "x1 = np.asarray(x)\n",
    "y1 = np.asarray(y)\n",
    "y2 = keras.utils.to_categorical(np.asarray(y), num_classes)\n",
    "\n",
    "classifier1 = SVC(kernel='linear', C=1.0, degree=1, gamma= 0.1)\n",
    "classifier1.fit(x1, y1)\n",
    "\n",
    "y_pred_mnist_svm_bg=classifier1.predict(X_test_svmrf)\n",
    "\n",
    "y_pred_usps_svm_bg=classifier1.predict(usps_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = RandomForestClassifier(n_estimators=100,criterion=\"entropy\",max_depth = 2,min_samples_split = 10)\n",
    "classifier2.fit(x1, y1)\n",
    "\n",
    "y_pred_mnist_rf_bg = classifier2.predict(X_test_svmrf)\n",
    "y_pred_usps_rf_bg = classifier2.predict(usps_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging using majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding class with maximum number of predictions that gives us the result of bagging using Majority Voting\n",
    "from collections import Counter\n",
    "import operator\n",
    "final=[]\n",
    "for i in range(len(y_pred_mnist_rf_bg)):\n",
    "    a=[]\n",
    "    a.append(ynew_mnist_nn_bg[i])\n",
    "    a.append(y_pred_mnist_svm_bg[i])\n",
    "    a.append(y_pred_mnist_rf_bg[i])\n",
    "    b=dict(Counter(a))\n",
    "    c=max(b.items(), key=operator.itemgetter(1))[0]\n",
    "    final.append(c)\n",
    "final_pred = np.asarray(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(ynew_mnist_nn_bg,final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred_mnist_svm_bg,final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred_mnist_rf_bg,final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=[]\n",
    "for i in range(len(y_pred_usps_rf_bg)):\n",
    "    a=[]\n",
    "    a.append(ynew_usps_nn_bg[i])\n",
    "    a.append(y_pred_usps_svm_bg[i])\n",
    "    a.append(y_pred_usps_rf_bg[i])\n",
    "    b=dict(Counter(a))\n",
    "    c=max(b.items(), key=operator.itemgetter(1))[0]\n",
    "    final.append(c)\n",
    "final_pred = np.asarray(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred_usps_rf_bg,final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(ynew_usps_nn_bg,final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_pred_usps_svm_bg,final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
